{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ede3380",
   "metadata": {},
   "source": [
    "# WEB SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83822cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff13e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://es.finance.yahoo.com/quote/EURUSD%3DX\"\n",
    "\n",
    "preciosdia = namedtuple('preciosdia', ['cierre_anterior',\n",
    "                                   'abrir',\n",
    "                                   'ofer',\n",
    "                                  ])\n",
    "precios = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)\n",
    "html = r.text\n",
    "html;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_soup = bs(html, 'html.parser')\n",
    "html_soup;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablaeurodolar = html_soup.find_all('table',\n",
    "                               class_=\"W(100%)\")\n",
    "tablaeurodolar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db313761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Tabla 1 - Cierre anterior, abrir y oferta\n",
    "tabla1 = html_soup.find_all('table', class_=\"W(100%)\")[0]\n",
    "filas_tabla1 = tabla1.find_all('tr')\n",
    "\n",
    "datos_tabla1 = {}\n",
    "for fila in filas_tabla1:\n",
    "    columnas = fila.find_all('td')\n",
    "    if len(columnas) == 2:\n",
    "        clave = columnas[0].text.strip()\n",
    "        valor = columnas[1].text.strip()\n",
    "        datos_tabla1[clave] = valor\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame([datos_tabla1])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43189cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import datetime\n",
    "\n",
    "# Leer el archivo Excel existente o crear uno nuevo si no existe\n",
    "try:\n",
    "    df = pd.read_excel('D:/archivo.xlsx')\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# Tabla 1 - Cierre anterior, abrir y oferta\n",
    "tabla1 = html_soup.find_all('table', class_=\"W(100%)\")[0]\n",
    "filas_tabla1 = tabla1.find_all('tr')\n",
    "\n",
    "datos_tabla1 = {}\n",
    "for fila in filas_tabla1:\n",
    "    columnas = fila.find_all('td')\n",
    "    if len(columnas) == 2:\n",
    "        clave = columnas[0].text.strip()\n",
    "        valor = columnas[1].text.strip()\n",
    "        datos_tabla1[clave] = valor\n",
    "\n",
    "# Obtener la fecha actual\n",
    "fecha_actual = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Añadir una nueva fila al DataFrame\n",
    "nueva_fila = pd.DataFrame([{\"Fecha\": fecha_actual, **datos_tabla1}])\n",
    "\n",
    "# Concatenar el DataFrame existente con la nueva fila\n",
    "df = pd.concat([nueva_fila, df], ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame en el archivo Excel\n",
    "with pd.ExcelWriter('D:/archivo.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "    df.to_excel(writer, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c0592",
   "metadata": {},
   "source": [
    "# Actividad en clase:\n",
    "\n",
    "1. Implementando Web Scraping, determinar el precio actual de los productos obtenidos del ejemplo de Mercado Libre para poder asignarlo en una nueva columna del dataFrame y luego otra columna nueva que contenga la diferencia de esos dos valores, lo que le permita a los usuarios conocer si el descuento es considerable o no.\n",
    "\n",
    "2. Consultar, revisar y aplicar beatiful soup a una página web la cual visite constantemente y quiera automatizar el proceso de acceso a la información (datos). Convertir las variables de interés en DataFrame y aplicar una consulta sencilla."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
